КРАТКОЕ ОПИСАНИЕ ПРОЕКТА:
Проект: Классификация опухолей на основе набора данных Breast Cancer Wisconsin

Описание:
Этот проект включает в себя:
1. Загрузку набора данных Breast Cancer Wisconsin и вывод заголовков на английском и русском, типов данных и первых 5 строк.
2. Обучение различных классификаторов с использованием нескольких гиперпараметров.
3. Оценку моделей с использованием различных метрик и вывод матрицы истинности.
4. Измерение времени, затраченного на обучение каждой модели и подбор гиперпараметров.
5. Обработку исключений и предупреждений, вывод всех ошибок и предупреждений в конце выполнения программы.
6. Выбор лучшей модели на основе метрик и лучших гиперпараметров.

Инструкции по использованию:
1. Установите необходимые библиотеки: `pandas`, `scikit-learn`, `catboost`, `lightgbm`, `xgboost`, `seaborn`.
2. Запустите `main.py` для выполнения всех шагов: загрузка данных, обучение моделей, оценка моделей и выбор лучшей модели.

Модули:
1. data_loader.py - Класс для загрузки и предварительной обработки данных.
2. model_trainer.py - Класс для обучения моделей и измерения времени обучения.
3. model_evaluator.py - Класс для оценки моделей и вывода матриц истинности.
4. main.py - Основной файл для запуска программы и обработки исключений.

ПОДРОБНОЕ ОПИСАНИЕ ПРОЕКТА:
Проект "Классификация опухолей на основе набора данных Breast Cancer Wisconsin" представляет собой анализ данных и классификацию 
опухолей с использованием различных методов машинного обучения. Проект включает несколько этапов: загрузка данных, обучение моделей, 
оценка их качества и выбор лучшей модели. Ниже представлено полное описание структуры проекта и основных модулей, а также их функций.

Структура проекта:
data_loader.py
model_trainer.py
model_evaluator.py
main.py
README.txt

Модули проекта:
1. data_loader.py
Описание:
Этот модуль отвечает за загрузку и предобработку данных из набора данных Breast Cancer Wisconsin.

Основные функции:
__init__(self): Инициализация объекта класса DataLoader.
load_data(self): Загрузка и предобработка данных, включая перевод заголовков на русский язык.
get_features_and_target(self): Возвращает признаки (X) и целевую переменную (y) из загруженного набора данных.

2. model_trainer.py
Описание:
Этот модуль отвечает за обучение моделей с использованием различных гиперпараметров и измерение времени обучения.

Основные функции:
__init__(self): Инициализация классификаторов и их гиперпараметров.
train_single_model(self, model_name, model, X, y): Обучение одной модели с использованием GridSearchCV и измерение времени.
train_models(self, X, y): Обучение всех моделей последовательно.
get_best_params(self): Возвращает лучшие гиперпараметры для каждой модели.
get_training_times(self): Возвращает время, затраченное на обучение каждой модели.

3. model_evaluator.py
Описание:
Этот модуль отвечает за оценку качества моделей, построение матриц истинности и выбор лучшей модели.

Основные функции:
__init__(self, models, X_test, y_test): Инициализация объекта класса ModelEvaluator.
evaluate_models(self): Оценивает модели по различным метрикам и строит матрицы истинности.
plot_confusion_matrix(self, model_name, y_pred): Строит матрицу истинности для заданной модели и предсказанных значений.
get_best_model(self): Возвращает лучшую модель на основе метрики ROC AUC.

4. main.py
Описание:
Основной файл для запуска программы. Он объединяет все модули и выполняет все этапы проекта: загрузка данных, обучение моделей, 
оценка моделей, выбор лучшей модели и обработка исключений.

Основные функции:
log_message(message): Функция для добавления сообщений об ошибках и предупреждениях в список.
custom_warning_handler(message, category, filename, lineno, file=None, line=None): Переопределение функции showwarning 
для фильтрации предупреждений.
FilteredStream: Класс для фильтрации информационных сообщений.
Основной блок кода выполняет следующие шаги: загрузка данных, разделение данных на обучающие и тестовые, обучение моделей, 
вывод времени обучения, оценка моделей, вывод лучших гиперпараметров, выбор лучшей модели и вывод всех предупреждений и ошибок в конце.


РЕЗУЛЬТАТЫ:

Тип данных каждого столбца:
Средний радиус                       float64
Средняя текстура                     float64
Средний периметр                     float64
Средняя площадь                      float64
Средняя гладкость                    float64
Средняя компактность                 float64
Средняя вогнутость                   float64
Средние вогнутые точки               float64
Средняя симметрия                    float64
Средняя фрактальная размерность      float64
Ошибка радиуса                       float64
Ошибка текстуры                      float64
Ошибка периметра                     float64
Ошибка площади                       float64
Ошибка гладкости                     float64
Ошибка компактности                  float64
Ошибка вогнутости                    float64
Ошибка вогнутых точек                float64
Ошибка симметрии                     float64
Ошибка фрактальной размерности       float64
Наихудший радиус                     float64
Наихудшая текстура                   float64
Наихудший периметр                   float64
Наихудшая площадь                    float64
Наихудшая гладкость                  float64
Наихудшая компактность               float64
Наихудшая вогнутость                 float64
Наихудшие вогнутые точки             float64
Наихудшая симметрия                  float64
Наихудшая фрактальная размерность    float64
Целевая переменная                     int32
dtype: object

Первые 5 строк:
   Средний радиус  Средняя текстура  Средний периметр  ...  Наихудшая симметрия  Наихудшая фрактальная размерность  Целевая переменная
0           17.99             10.38            122.80  ...               0.4601                            0.11890                   0
1           20.57             17.77            132.90  ...               0.2750                            0.08902                   0
2           19.69             21.25            130.00  ...               0.3613                            0.08758                   0
3           11.42             20.38             77.58  ...               0.6638                            0.17300                   0
4           20.29             14.34            135.10  ...               0.2364                            0.07678                   0

......

Начало обучения Gradient Boosting...
Обучение Gradient Boosting завершено. Время: 29.75 секунд.
Начало обучения CatBoost...
Обучение CatBoost завершено. Время: 65.63 секунд.
Начало обучения AdaBoost...
Обучение AdaBoost завершено. Время: 10.51 секунд.
Начало обучения Extra Trees...
Обучение Extra Trees завершено. Время: 4.09 секунд.
Начало обучения Quadratic Discriminant Analysis...
Обучение Quadratic Discriminant Analysis завершено. Время: 0.05 секунд.
Начало обучения LightGBM...
Обучение LightGBM завершено. Время: 4.54 секунд.
Начало обучения K Neighbors...
Обучение K Neighbors завершено. Время: 0.16 секунд.
Начало обучения Decision Tree...
Обучение Decision Tree завершено. Время: 0.32 секунд.
Начало обучения Dummy Classifier...
Обучение Dummy Classifier завершено. Время: 0.03 секунд.
Начало обучения SVM...
Обучение SVM завершено. Время: 190.60 секунд.

Время обучения для каждой модели:
Gradient Boosting: 29.75 секунд
CatBoost: 65.63 секунд
AdaBoost: 10.51 секунд
Extra Trees: 4.09 секунд
Quadratic Discriminant Analysis: 0.05 секунд
LightGBM: 4.54 секунд
K Neighbors: 0.16 секунд
Decision Tree: 0.32 секунд
Dummy Classifier: 0.03 секунд
SVM: 190.60 секунд

Начало оценки модели Gradient Boosting...
Начало оценки модели CatBoost...
Начало оценки модели AdaBoost...
Начало оценки модели Extra Trees...
Начало оценки модели Quadratic Discriminant Analysis...
Начало оценки модели LightGBM...
Начало оценки модели K Neighbors...
Начало оценки модели Decision Tree...
Начало оценки модели Dummy Classifier...
Начало оценки модели SVM...

                             Model  Accuracy  Precision    Recall  F1 Score   ROC AUC
0                Gradient Boosting  0.956140   0.958333  0.971831  0.965035  0.994759
1                         CatBoost  0.973684   0.972222  0.985915  0.979021  0.995414
2                         AdaBoost  0.973684   0.972222  0.985915  0.979021  0.995414
3                      Extra Trees  0.973684   0.972222  0.985915  0.979021  0.997380
4  Quadratic Discriminant Analysis  0.956140   0.971429  0.957746  0.964539  0.987881
5                         LightGBM  0.964912   0.958904  0.985915  0.972222  0.993449
6                      K Neighbors  0.956140   0.945946  0.985915  0.965517  0.996397
7                    Decision Tree  0.947368   0.957746  0.957746  0.957746  0.943990
8                 Dummy Classifier  0.622807   0.622807  1.000000  0.767568  0.500000
9                              SVM  0.956140   0.945946  0.985915  0.965517  0.990829

Лучшие гиперпараметры для каждого классификатора:
{
   "Gradient Boosting":{
      "learning_rate":0.1,
      "n_estimators":200
   },
   "CatBoost":{
      "depth":8,
      "iterations":200
   },
   "AdaBoost":{
      "learning_rate":1,
      "n_estimators":100
   },
   "Extra Trees":{
      "max_features":"log2",
      "n_estimators":200
   },
   "Quadratic Discriminant Analysis":{
      
   },
   "LightGBM":{
      "learning_rate":0.1,
      "n_estimators":100
   },
   "K Neighbors":{
      "n_neighbors":7
   },
   "Decision Tree":{
      "max_depth":20
   },
   "Dummy Classifier":{
      
   },
   "SVM":{
      "C":10
   }
}

Лучшая модель:
Model        Extra Trees
Accuracy        0.973684
Precision       0.972222
Recall          0.985915
F1 Score        0.979021
ROC AUC          0.99738

ВЫВОДЫ НА ОСНОВАНИИ ПОЛУЧЕННЫХ ДАННЫХ:
Классификатор Extra Trees (Extra Trees Classifier) оказался лучшим в этом случае благодаря нескольким особенностям и преимуществам:

1. Случайные признаки и разбиения: Extra Trees использует случайные подмножества признаков для построения каждого дерева, 
а также случайные разбиения на каждом узле. Это помогает снизить переобучение и улучшить обобщающую способность модели.

2. Большее разнообразие деревьев: Поскольку Extra Trees выбирает случайные разбиения, каждое дерево в ансамбле становится 
более независимым. Это приводит к более разнообразным деревьям, что улучшает производительность ансамбля.

3. Устойчивость к шуму: Extra Trees устойчив к шуму в данных, что означает, что он может лучше справляться с реальными данными, 
которые часто содержат шум и выбросы.

4. Эффективность вычислений: Extra Trees обычно требует меньше вычислительных ресурсов, чем другие методы ансамблей, 
такие как Random Forest, поскольку он не ищет оптимальные разбиения на каждом узле, а выбирает случайные разбиения.

5. Высокая точность и обобщающая способность: В случае данных Breast Cancer Wisconsin, Extra Trees мог лучше выявить 
закономерности и связи между признаками и целевой переменной, что привело к высокой точности и обобщающей способности.

Эти особенности делают Extra Trees мощным инструментом для классификации в задачах, где важна высокая точность и устойчивость к шуму.